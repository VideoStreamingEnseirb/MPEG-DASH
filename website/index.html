<!DOCTYPE html>
<html>

<head>
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
		integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
	<link rel="stylesheet" type="text/css" href="style.css">
	<title>MPEG-DASH Streaming Protocol</title>
	<link rel="shortcut icon" type="image/png" href="../images/mpeg-dash-4.png" />
	<!-- Demo scripts -->
	<script src="../demo/sourcedash/dash.all.debug.js"></script>
	<script class="code" src="../demo/index_remote_server.js"></script>
</head>

<body>
	<nav class="navbar navbar-light bg-dark fixed-top">
		<a class="navbar-brand" id="nav">RSC 2019/2020</a>
		<form class="form-inline">
			<a class="nav-item nav-link" href="#">HLS</a>
			<a class="nav-item nav-link" href="#">MPEG-DASH</a>
			<a class="nav-item nav-link" href="#">RTMP</a>
			<a class="nav-item nav-link" href="#">RTSP+RTP</a>
			<a class="nav-item nav-link" href="#">WebRTC</a>
		</form>
	</nav>

	<nav class="navbar navbar-light fixed-top" id="navbar2">
		<a class="navbar-brand" id="nav2">MPEG-DASH</a>
		<form class="form-inline">
			<a class="nav-item nav-link" href="#presentation">Protocol Presentation</a>
			<a class="nav-item nav-link" href="#demonstration">Demonstration</a>
			<a class="nav-item nav-link" href="#howto">HowTo</a>
		</form>
	</nav>

	<div class="container">
		<div id="presentation" class="anchor"></div>
		<div class="card">
			<div class="card-header">
				<h2> Protocol Presentation </h2>
			</div>
			<div class="card-body">
				<h3 class="card-title">MPEG-DASH</h3>
				<div class="card-text">
					Click <a href="https://mpeg.chiariglione.org/standards/mpeg-dash">&gt;here&lt;</a> for the Official
					Website of MPEG-DASH.
					<div class="texte-illustration">
						<p class="flotteg">
							<img src="../images/Bitrate_streaming.jpg" alt="Bitstrate streaming" width=100%>
						</p>
						<p>

							Dynamic Adaptive Streaming over HTTP, or MPEG-DASH is an adaptive streaming for media
							content on internet.
							It is an international standard since November 2011, created by the Moving Picture Experts
							Group (MPEG) with the collaboration of almost a dozen organizations.
							It is based on the derivation of content in several versions having distinct quality and
							characteristics and then cut into short segments.
							A manifest file in .xml format (the Media Presentation Description (MPD)) gives the client
							the information necessary to request each segment individually from conventional HTTP web
							servers. <br>
							The behavior of the client isn’t normalized, this way the provider of the service can adapt
							it to its needs.
							In practice, the choice of an adaptive bitrate streaming is ever done, so the selection of
							each segment is done by the client while the content is being played by choosing the maximum
							bit rate that avoids stalls or rebuffering events.
							This method adapts the stream to the network conditions when changing, and provides high
							quality streaming. The use of HTTP makes possible to rely on the existing web infrastructure
							and the existing network libraries on devices connected to the Internet. <br>
							The main advantage of using MPEG-DASH is the quality it provides, while the main
							disadvantage is that it is not natively supported by some browsers and devices like
							IE&#x3C;11 or iOS.

						</p>
					</div>

					<h5>Protocol stack</h5>
					<div class="texte-illustration">
						<p class="flotted">
							<img src="../images/Protocol stack.jpg" alt="Protocol stack" width=100%>
						</p>
						<p>
							The protocol stack of MPEG-DASH can be divided into two possibilities: one connected and one
							not connected.
							The network layer is the same for both possibilities: IP. It is on the transport layer that
							the protocol stack splits in two: <br>
							- The connected version uses TCP as transport layer, followed by TLS 1.2 for the security
							layer and finally HTTP/2 for the application layer. <br>
							- The non-connected version uses UDP as transport layer, combined with QUIC which extends
							itself from the transport layer to the application layer, which is shared with HTTP/2 API.
							<br>
							<br>
							For more information about IP, TCP, UDP, TLS, find it in the different RFCs: <br>
							<ul>
								<li><a href="https://www.rfc-editor.org/info/rfc791">IPv4: Internet Protocol version 4</a></li>
							
								<li><a href="https://www.rfc-editor.org/info/rfc793">TCP: Transmission Control Protocol</a></li>

							<li><a href="https://www.rfc-editor.org/info/rfc768">UDP: User Datagram Protocol</a> </li>
							
							<li><a href="https://www.rfc-editor.org/info/rfc5246">TLS v1.2: Transport Layer Security
								version 1.2</a> </li>
							</ul>

						</p>
					</div>

					<h5>Media Presentation Description</h5>
					<img src="../images/MPD schema.jpg" alt="MPD" width=100%>
					<br>
					<p>
						Media Presentation Description (or MPD) is an XML document containing information about the data
						segments. It is divided into multiple parts: <br>
						<ul>
							<li> A period ID: determines the type of information (audio, video, subtitle)</li>
							<li> An adaptation set: determines the quality and bitrate of the segment</li>
							<li> A representation: contains all the segment information</li>
							<li> A segment information: contains the URL of each segment and provides additional information about the segment in itself (beginning time, end time, …)</li>
						</ul>
						With a MPD, it is easy to select the segment wanted, with the quality/bitrate/… needed.
					</p>

					<h5>General Fonctionment</h5>

					<div class="texte-illustration">
						<p class="flotted">
							<img src="../images/Fonctionment.jpg" alt="Fonctionment" width=100%>
						</p>
						<p>

							Playback of content via MPEG-DASH is as follows:
						</p>
						<div class="texte-illustration">
							<p class="flotteg" id=numeros>
								<img src="../images/1.png" alt="MPD"  width=100%>
							</p>
							<p>
								First, the client requests the Media Presentation Description (MPD) associated with the
								desired content from the MPD server and receives it.
								This MPD is parsed by the client and provides it with the data necessary for the
								acquisition and processing of the segments.

							</p>
						</div>

						<div class="texte-illustration">
							<p class="flotteg" id=numeros>
								<img src="../images/2.png" alt="MPD" width=100%>
							</p>
							<p>
								Everything is supervised by a heuristic control.

							</p>
						</div>

						<div class="texte-illustration">
							<p class="flotteg" id=numeros>
								<img src="../images/3.png" alt="MPD" width=100%>
							</p>
							<p>
								The HTTP client then begins to request one by one the segments from the servers
								concerned, taking into account the network conditions
								for the choice of bit rate and quality in order to get the higher quality and bit rate
								possible avoiding stalls or rebuffering.

							</p>
						</div>

						<div class="texte-illustration">
							<p class="flotteg" id=numeros>
								<img src="../images/4.png" alt="MPD" width=100%>
							</p>
							<p>
								The segments are parsed using a segment parser.

							</p>
						</div>

						<div class="texte-illustration">
							<p class="flotteg" id=numeros>
								<img src="../images/5.png" alt="MPD" width=100%>
							</p>
							<p>
								The segments are finally played by the player.

							</p>
						</div>

						<p>

							An important point is that the following segments are requested, received and processed
							while playing the previous ones.
							This allows to display the content without interruption and to adapt in real time to the
							network.

						</p>

					</div>
					</p>
				</div>

				<h5>Use Cases</h5>

					<div class="texte-illustration">
						<p> MPEG-DASH can be use in many cases. Here are a few examples:
							<ul>
							  <li>On-Demand, Live and time-shift streaming</li>
							  <li>Delivery of same content on many screens</li>
							  <li>Delivery of any multimedia content (2D, graphics, subtitles, text, etc.)</li>
							  <li>Support of multiple languages and different audio configuration</li>
							</ul>
						</p>
					</div>

					<h5>Existing projets</h5>

					<div class="texte-illustration">
						<p> 
							<ul>
							  <li>
							  	<a href="https://github.com/Dash-Industry-Forum/dash.js/wiki/"> Dash.js </a> (framework for building video and audio players that play back MPEG-DASH content using client-side JavaScript libraries)
							  </li>
							  <li>
							  	<a href="https://github.com/google/shaka-player/"> Shaka </a> (open source dash player from Google)
							  </li>
							  <li>
							  	<a href="https://github.com/bitmovin/libdash"> Libdash </a> (open-source library to use MPEG-DASH standard)
							  </li>
							  <li>
							  	<a href="https://bitmovin.com/video-player"> Bitmovin </a> (Live or on-demand transcoding of video and web-based MPEG-DASH players in HTML5 or Flash)
							  </li>
							</ul>
						</p>
					</div>
			</div>
		</div>

		<div id="demonstration" class="anchor"></div>
		<div class="card" id="">
			<div class="card-header">
				<h2> Demonstration </h2>
			</div>
			<div class="card-body">
				<div class="card-text">
					URL MDP file:
					<a
						href="http://rdmedia.bbc.co.uk/dash/ondemand/testcard/1/client_manifest-events.mpd">http://rdmedia.bbc.co.uk/dash/ondemand/testcard/1/client_manifest-events.mpd</a>
				</div>
				<br>
				<div id="container">
					<div class="video-container" id="colonne1">
						<video data-dashjs-player controls="true"></video>
					</div>
					<fieldset id="colonne2">
						<h5>Video Fragment</h5>
						<div id="trace" placeholder="Trapped events will be displayed here"></div>
					</fieldset>
					<fieldset id="colonne3">
						<h5>Audio Fragment</h5>
						<div id="trace2" placeholder="Trapped events will be displayed here"></div>
					</fieldset>
					<fieldset>
						<br>
						<h5>Configuration parameters</h5>
						<div>
							Max stable buffer (seconds): <input type="number" id="stableBuffer" value="20"> (Current
							Buffer: <span id="currentBufferLevel" )>0</span> seconds)
							<div class="description">The time that the internal buffer target will be set to post
								startup/seeks (NOT
								top quality).</div>
						</div>
						<div>
							Buffer lenght at top quality (seconds): <input type="number" id="topQualityBuffer"
								value="20">
							<div class="description">The time that the internal buffer target will be set to once
								playing the top
								quality.</div>
						</div>
						<div>
							Max selectable bitrate (Kbps): <input type="number" id="maxBitrate" value="5000">
							(Downloading bitrate:
							<span id="reportedBitrate" )>0</span>)
							<div class="description">The maximum bitrate selectable by the ABR algorithms will choose.
								Use -1 for no
								limit.</div>
						</div>
						<div>
							Min selectable bitrate (Kbps): <input type="number" id="minBitrate" value="-1">
							<div class="description">The minimum bitrate that the ABR algorithms will choose. Use -1 for
								no limit.
							</div>
						</div>
						<div>
							Limit Bitrate By Portal Size: <input type="checkbox" id="limitByPortal">
							<div class="description">If true, the size of the video portal will limit the max chosen
								video
								resolution.</div>
						</div>
						<div>
							<button onclick="applySettings()">Apply changes</button>
						</div>
					</fieldset>
				</div>
				<script>
					document.addEventListener("DOMContentLoaded", function () {
						init();
					});
				</script>
			</div>
		</div>

		<div id="howto" class="anchor"></div>

		<div class="card">
			<div class="card-header">
				<h2> HowTo </h2>
			</div>

			<div class="card-body">
				<h3>Server Part Deployment</h3>
				<div class="texte-illustration">
					<h5> Prerequisities </h5>
					<p>
						You will need ffmpeg, which is a tool for handling video, audio, and other multimedia files
						and streams. <br>
						Have a look to their website for more information: <a
							href="https://www.ffmpeg.org">https://www.ffmpeg.org</a>

						<br>
						<br>
						Download and install ffmpeg with:
						<br>
						<br>
						<code>sudo apt-get install ffmpeg</code>
						<br>
						<br>
						If you want to make it locally, make sure you have an HTTP server installed on your computer, as
						Apache2.
					</p>
					<h5> Create MPD file and DASHable segments</h5>
					<p>
						Go into your working directory:
						<br>
						<br>
						<code>serverVideo</code>
						<br>
						<code>cd serverVideo</code>
						<br>
						<br>
						Paste your file <code>in.video</code> (the video you want to dash) into the folder serverVideo.
						<br>
						<br>
						Create the audio file with this command:
						<br>
						<br>
						<code> ffmpeg -i in.video -vn -acodec libvorbis -ab 128k -dash 1 my_audio.webm</code>
						<br>
						<br>
						Create then the dashable segment in different qualities:
						<br>
						<code> ffmpeg -i presentation-filiere-telecommunications.mp4 -c:v libvpx-vp9 -keyint_min 150 \<br>
							-g 150 -tile-columns 4 -frame-parallel 1 -f webm -dash 1 \<br>
							-an -vf scale=160:90 -b:v 250k -dash 1 video_160x90_250k.webm \<br>
							-an -vf scale=320:180 -b:v 500k -dash 1 video_320x180_500k.webm \<br>
							-an -vf scale=640:360 -b:v 750k -dash 1 video_640x360_750k.webm \<br>
							-an -vf scale=640:360 -b:v 1000k -dash 1 video_640x360_1000k.webm \<br>
							-an -vf scale=1280:720 -b:v 1500k -dash 1 video_1280x720_1500k.webm</code>
						<br>
						<br>
						With this command line, you don't fragment the video, but you create 5 videos in different
						formats. Check the options available in ffmpeg to see the fragmentation.
						<br>
						<br>
						Create the MPD file:
						<br>
						<code>
							ffmpeg \<br>
							-f webm_dash_manifest -i video_160x90_250k.webm \<br>
							-f webm_dash_manifest -i video_320x180_500k.webm \<br>
							-f webm_dash_manifest -i video_640x360_750k.webm \<br>
							-f webm_dash_manifest -i video_1280x720_1500k.webm \<br>
							-f webm_dash_manifest -i my_audio.webm \<br>
							-c copy \<br>
							-map 0 -map 1 -map 2 -map 3 -map 4 \<br>
							-f webm_dash_manifest \<br>
							-adaptation_sets "id=0,streams=0,1,2,3 id=1,streams=4" \<br>
							my_video_manifest.mpd<br>
						</code>
						<br>

					</p>
				</div>
				<h3>Player Part Deployment</h3>
				<div>
					<h5> Prerequisities </h5>
					We used the library DashJS to settle our dash player. Have a look on their
					<a href="https://github.com/Dash-Industry-Forum/dash.js"> GitHub</a>. <br> <br>

					
					<h5> Integrate a dash player in your website</h5>

					You can integrate the dash player simply by adding those lines (in an html file): <br><br>

					<img src="../images/codehtml.png" alt="Dash player integration">
					<br>
					<br>
					
					Thanks to DashJS library, you can modify option of the dash player, have a look to our demo in our GitHub.

				</div>
				<br>
				<h3 class="card-title">Link to GitHub repository</h3>
				<a href="https://github.com/VideoStreamingEnseirb/MPEG-DASH.git">GitHub repository</a>
			</div>
		</div>
	</div>
</body>

</html>